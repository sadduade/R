---
title: "HW2. Hypothesis testing"
output: html_document
---

# HW2. Тестирование гипотез. t-test. Доверительные интервалы. Корреляции 

Перед сдачей домашнего задания рекомендуем запустить Run All или сгенерировать html- или pdf-страницу с помощью Knit, чтобы убедиться, что в финальной версии весь ваш код будет запускаться без проблем.

Файл Rmd вы можете а) положить в свой приватный репозиторий da4clcourse на GitHub (в корне репозитория под именем HW1.Rmd). Дайте доступ преподавателю и ассистенту к приватному репозиторию (пригласите @olesar и @The-One-Who-Speaks-and-Depicts) или б) выслать преподавателю на почту olyashevskaya@hse.ru с темой da4clcourse.

## 1. Частотность и фонетика

В этом разделе используются те же данные, что и в прошлом домашнем задании. Вы можете пропустить описание, если знакомы с датасетом.  

Во многих лингвистических исследованиях отмечается, что часто используемые в языке слова звучат короче, а при их произнесении наблюдается редукция и коартикуляция. Работа Fabian Tomaschek et al. (2018) исследует гипотезу, что моторные навыки произнесения улучшаются с опытом, который, в свою очередь, напрямую связан с частотностью слова. Ученые попросили испытуемых (17 бакалавров университета Тюбингена, 8 мужчин и 9 женщин) прочитать вслух немецкие глаголы, содержащие звук [a:] в основе. Испытуемые были поставлены в экспериментальные условия, которые исподволь заставляли их читать быстрее или медленнее (slow/fast condition).

В этом задании мы просим вас сравнить длину звучания всего слова целиком, а также длину звучания интересующего ученых сегмента (звука [a:]) в условиях slow и fast. Хотя логично предположить, что в условии fast произнесение и слов, и сегментов будет короче, все же нужно убедиться, что данные это подтверждают, прежде чем переходить к более сложному анализу по сути вопроса. Кроме того, мы будем уверены, что экспериментальные условия были должным образом соблюдены, ученые не запутались в кодировании данных и документировали результаты корректно.

Интересующие нас переменные:

LogDurationW - log-transformed word duration (логарифм длины произнесения слова)
LogDurationA - log-transformed segment duration (логарифм длины произнесения сегмента)
Cond - condition: slow vs. fast (условие).

Ссылка на данные [link](https://raw.githubusercontent.com/LingData2019/LingData2020/master/data/dur_word_frequency.csv)

```{r load-data}
library(tidyverse)
library(skimr)

dur_word_freq <- read_csv('https://raw.githubusercontent.com/LingData2019/LingData2020/master/data/dur_word_frequency.csv')
```

### 1.0 t-test

С помощью t-критерия Стьюдента мы хотим определить статистическую значимость различия значений применительно к следующим переменным:  

(a) word durarion in fast condition and word duration in slow condition,

(b) segment duration in fast condition and segment duration in slow condition. 

Другими словами, мы хотим проверить, что различие этих длительностей имеет место не только на выборках, но и в генеральной совокупности.

#### 1.1 Гипотезы 

В первую очередь, сформулируйте нулевую гипотезу (H_0) и альтернативную гипотезу (H_1). Если для выполнения задания нужно сформулировать несколько H_0 и H_1, сделайте это, продублировав этот и следующий разделы (1.1а, 1.2a, 1.3.a, 1.1b, 1.2b и т.д.)  

```
H0: word durarion in fast condition = word duration in slow condition 

H1: segment duration in fast condition != segment duration in slow condition
```

#### 1.2 Тест  

Загрузите данные и примените `t.test` для проверки гипотез.  

```{r t-test}
t_word <- t.test(LogDurationW ~ Cond, data = dur_word_freq, paired = FALSE)
print(t_word)


t_segment <- t.test(LogDurationA ~ Cond, data = dur_word_freq, paired = FALSE)
print(t_segment)
```


#### 1.3 Интерпретация  

Интерпретируйте результаты t-теста. Включите в вывод t-статистику, степени свободы и p-values. Можно ли заключить, что имеется различие в длительности слов в быстрых и медленных условиях в генеральной совокупности? Можно ли заключить то же самое в отношении длительности сегментов?  

```
В обоих случаях можно отвергуть нулевую гипотезу. Среднее первой выборки выше среднего второй. В первом случае: t = -11.562, df = 829.89, p-value < 2,2e-16. Во втором: t = -7.5116, df = 822.67, p-value = 1.523e-13.
```

### 2. Дискуссия 

Возможно, применение t-test в чистом виде является не лучшей опцией для решения задачи 1.0. Если вам тоже так кажется, приведите аргументы против его использования и предложите другое решение. 

```
Здесь есть только две группы - slow и fast, данные распределены неравномерно, есть выбросы, поэтому можно попробовать тест Манна-Уитни.

```

#### 2.1 Код для решения    

Напишите код, который может помочь в аргументации и покажет другое решение. 

```{r} 
shapiro.test(dur_word_freq$LogDurationW)
shapiro.test(dur_word_freq$LogDurationA) #есть выбросы
qqnorm(dur_word_freq$LogDurationW,
main = "Q-Q plot for LogDurationW") 
qqline(dur_word_freq$LogDurationW) #данные созависимы
qqnorm(dur_word_freq$LogDurationA, 
main = "Q-Q plot for LogDurationA")
qqline(dur_word_freq$LogDurationA)
observations_per_participant <- 
dur_word_freq %>% count(Participant) 
print(observations_per_participant)
wilcox.test(LogDurationW ~ Cond, data = dur_word_freq, paired = FALSE)
wilcox.test(LogDurationA ~ Cond, data = dur_word_freq, paired = FALSE)

#Таким образом можно увиедть статистически значимое различие в word duration в fast и slow условиях, а также в segment duration 
```


### 3. Доверительный интервал

#### 3.1 Формула в явном виде 

Ниже приведена формула для вычисления 95% доверительного интервала:

$$
\mathrm{CI} = \left[\bar{x} - 1.96\times \frac{\mathop{\mathrm{sd}}(x)}{\sqrt{n}},\ \bar{x} + 1.96\times \frac{\mathop{\mathrm{sd}}(x)}{\sqrt{n}}\right].
$$
Используйте ее для нахождения 95% доверительного интервала для популяционной средней длительности слова (средней в генеральной совокупности).  


```{r ci-formula}
x<- mean(dur_word_freq$LogDurationW)
sd_x <- sd(dur_word_freq$LogDurationW)
n <- length(dur_word_freq$LogDurationW)

critical_value <- qnorm(0.975)
margin_of_error <- critical_value * (sd_x / sqrt(n))
confidence_interval <- c(x - margin_of_error, x + margin_of_error)

print(confidence_interval)
```


#### 3.2 Функция `t.test`

Примените функцию `t.test` к той же переменной, чтобы узнать доверительный интервал среднего. 

```{r ci-ttest}
t.test(dur_word_freq$LogDurationW)
```

Совпадают ли результаты вычислений в 2.1 и 2.2?
Нет

#### 3.3 Другие уровни доверия  

С помощью функции `MeanCI` из пакета `DescTools` найдите 99% доверительный интервал для той же переменнной. Он шире или уже, чем 95% CI?  

Подсказка: используйте аргумент `conf.level`. 

```{r ci-99}
library(DescTools)
confidence_interval_99 <- MeanCI(dur_word_freq$LogDurationW, conf.level = 0.99)

print(confidence_interval_99)

```


## 4. В каком возрасте дети усваивают слова? 

#### Практика в Tydyverse

Data: https://www.kaggle.com/rtatman/when-do-children-learn-words?select=main_data.csv

Основная таблица включает информацию о 732 словах норвежского языка и возрасте их усвоения детьми (age of acquisition). Другая таблица включает дополнительную информацию о частотности слов по данным веб-корпуса (Norwegian Web as Corpus) и данным разговоров взрослых с детьми.

Релевантные переменные (main data):

**Translation**: английский перевод норвежского слова

**AoA**: возраст усвоения в месяцах (в среднем, в каком возрасте слово усваивается детьми)

**VSoA**: сколько других слов знает "обобщенный" ребенок к моменту усвоения данного слова (округленно к ближайшему десятку)

**Broad_lex**: часть речи данного слова (в широком понимании) 

**CDS_Freq**: частота, с которой взрослый-носитель норвежского языка обращается к ребенку

Релевантные переменные (Norwegian CDS Frequency):

**Translation**: английский перевод норвежского слова

**Freq_NoWaC**: частота по данным корпуса NoWaC (интернет-коммуникация)

**Freq_CDS**: частота слова (по материалам двух норвежских корпусов CHILDES) при обращении к ребенку

NB! Все остальные переменные должны быть удалены из данных.  

NB! Столбцы 'Freq_CDS' and 'CDS_Freq' - это одно и то же. 

#### Данные 

#### 4.1 
Прочитайте обе таблицы   

```{r}
norway_main <- read_csv('main_data.csv')
norway_CDS <- read_csv('Norwegian_CDS_frequency.csv')

norway_main <- na.omit(norway_main)
norway_CDS <- na.omit(norway_CDS)
```

#### 4.2 
Оставьте только необходимые для последующего исследования переменные.

```{r}
norway_main <- norway_main[, c("Translation", "AoA", "VSoA", "Broad_lex", "CDS_freq")]
norway_CDS <- norway_CDS[, c("Translation", "Freq_NoWaC", "Freq_CDS")]
```

#### 4.3  
Объедините две таблицы в общий датафрейм/тиббл под названием 'norw_words'. 

NB! В вашем датафрейме не должно быть дублирования столбцов. 

```{r}
norway_main %>% 
  inner_join(norway_CDS) -> norw_words

norw_words %>%
 group_by_all() %>%
 filter(n() == 1) -> norw_words

norw_words <- subset(norw_words, select = -Freq_CDS)

norw_words
```

#### 4.4  
Оставьте только 15 первых строк 
 
```{r}
norw_words_15 <- head(norw_words, 15)
norw_words_15
```


#### 5. Преобразования данных 

#### 5.1  
Создайте тиббл 'freq_statistics', используя 3 столбца из (полного) тиббла `norw_words`: 'Translation', 'CDS_Freq', 'Freq_NoWaC'. Затем с помощью функций `pivot_longer`/`pivot_wider` измените формат тиббла с "широкого" на "узкий" или наоборот (данные подскажут вам, с какого на какой менять).

```{r}
freq_statistics <- norw_words[, c("Translation", "CDS_freq", "Freq_NoWaC")]

freq_statistics %>%
 pivot_longer(!Translation, names_to = "Freq", values_to = "count") 
```

#### 5.2  
Получите строковый вектор (string vector output) с информацией о классах переменных в тиббле. 

```{r}
variable_classes <- sapply(freq_statistics, function(x) paste(class(x), collapse = "/"))

print(variable_classes)
```

#### 5.3  
Представьте ту же информацию как датафрейм (dataframe). 

```{r}
variable_classes_df <- data.frame(Variable = names(freq_statistics), Class = variable_classes, row.names = NULL)
print(variable_classes_df)
```

#### 5.4  
Конвертируйте значения из столбцов `CDS_Freq` и `Freq_NoWaC` тиббла `freq_statistics` в числовые (numeric). 

```{r}
freq_statistics <- freq_statistics %>%
  mutate(CDS_freq = as.numeric(CDS_freq),
         Freq_NoWaC = as.numeric(Freq_NoWaC))

freq_statistics
```

#### 5.5 
Получите средние значения всех числовых типов переменных в `norw_words`.

```{r}
norw_words <- norw_words %>%
  mutate(CDS_freq = as.numeric(CDS_freq),
         Freq_NoWaC = as.numeric(Freq_NoWaC),
         AoA = as.numeric(AoA),
         VSoA = as.numeric(VSoA))

numeric_cols <- norw_words[sapply(norw_words, is.numeric)]
average_values <- colMeans(numeric_cols, na.rm = TRUE)
average_values
```

#### 5.6 
Создайте вложенную структуру (nested table) по столбцу `Translation`.
 
```{r}
nested_table <- norw_words %>%
  group_by(Translation) %>%
  nest()

print(nested_table)
```

#### 6.1 Корреляционный анализ  

Из доступных данных, выберите несколько переменных (более двух) для проведения корреляционного анализа, визуализируйте тепловую карту или другой тип коррелограммы. 

```{r}
library(corrplot)

cor_data <- norw_words %>%
  select(AoA, VSoA, Freq_NoWaC, Freq_CDS)

lapply(cor_data, shapiro.test)
```

#### 6.2 
Выводы  

В поле ниже сформулируйте ваши выводы, приведите p-values и другие необходимые статистические метрики. 

Корреляционный анализ показал, что можно отвергнуть нулевую гипотезу (τ = 0.93, p-value = 0.00). Также не обнаружена связь между значениями переменных Freq_NoWaC и Freq_CDS (τ = 0.50, p-value = 0.00).```


```